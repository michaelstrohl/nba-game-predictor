{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798e8270",
   "metadata": {},
   "source": [
    "# NBA Game predictor\n",
    "\n",
    "## Consists of the Model and the App\n",
    "\n",
    "### Goal of the Model:\n",
    "\n",
    "**Given two teams and their list of per game stats and other factors, output the probabilities each team wins**\n",
    "\n",
    "### Goal of the App:\n",
    "\n",
    "**Given two teams and the day before the game (Home, Away, Day), output the the probabilities each team wins based off the Models**\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. Creating The Model\n",
    "    1. Retrieve data using the [nba_api](https://github.com/swar/nba_api)\n",
    "    2. Adjust data and add features so each row includes each game and the respective per game stats for each team before the game and the outcome of the game\n",
    "    3. Train and test the model on this data\n",
    "2. Creating The  App\n",
    "    1. Retrieve the current years gamelogs\n",
    "    2. Adjust data and add features so each row includes the teams most up to date current per game stats\n",
    "    3. Create function that takes in a team and outputs the probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222371f3",
   "metadata": {},
   "source": [
    "## 1. Creating The Model\n",
    "\n",
    "### A. Retrieve data using nba_api\n",
    "\n",
    "**First Lets import our nessecarry libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7c51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import teamgamelog\n",
    "from nba_api.stats.static import teams\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6964ec5",
   "metadata": {},
   "source": [
    "- We will be using each teams game logs for a particular season\n",
    "- We also need a list of each team to itterate for\n",
    "- And a sleep function so we dont get timed out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242b2d8",
   "metadata": {},
   "source": [
    "**While we are at it lets import our other libraries too**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c96729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8244b3",
   "metadata": {},
   "source": [
    "- We use pandas for data analysis\n",
    "- Numpy for Linear Algebra\n",
    "- Seaborn for data visualization\n",
    "- Matplotlib for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2366d39",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13097ae8",
   "metadata": {},
   "source": [
    "**Next lets get a dictionary with each teams info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a8e1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1610612737,\n",
       " 'full_name': 'Atlanta Hawks',\n",
       " 'abbreviation': 'ATL',\n",
       " 'nickname': 'Hawks',\n",
       " 'city': 'Atlanta',\n",
       " 'state': 'Atlanta',\n",
       " 'year_founded': 1949}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_dict = teams.get_teams()\n",
    "team_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ce511",
   "metadata": {},
   "source": [
    "**Now we can itterate through each team for a select season and create a dataframe for all teams for that season**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584403bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for team in team_dict:\n",
    "    #print(team[\"full_name\"])\n",
    "    gamelogobj = teamgamelog.TeamGameLog(team_id = str(team[\"id\"]), season = \"2014\")\n",
    "    gamelogdf = gamelogobj.get_data_frames()[0]\n",
    "    df = pd.concat([df, gamelogdf])\n",
    "    sleep(.750) #Need to pause between loops so no timeout occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586d4a1",
   "metadata": {},
   "source": [
    "**Now I admit the issue with the current set up in this Notebook:** \\\n",
    "In order to get a complete data frame of multiple seasons is by running this for each season you want, \\\n",
    "then individually adjusting each seasons data and features, \n",
    "then finally concatenating all of those data frames. \\\n",
    "\\\n",
    "This is because when aggregating previous stats, only Game_ID's value (or Games left) is looked at so other years stats would be aggregated also.\\\n",
    "\\\n",
    "In the future this can be fixed by putting all the functions into a for loop and iterating through for each season you want, \\\n",
    "or by adding a season feature and adjusting the if statements to also match the correct season. \\\n",
    "Other thought is using Game_ID... it is formated to include the last two digits of the year and a uinque game number for that year.\n",
    "\\\n",
    "\\\n",
    "For now you can just download the complete dataframe (Seasons 2014 - 2018) and skip over running this next section of the notebook to save time. \\\n",
    "You can read in the file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a06905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.read_csv(\"complete_games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43353768",
   "metadata": {},
   "source": [
    "## B. Adjust Data and Add Features\n",
    "\n",
    "#### The data we currently have:\n",
    "- 2 rows for each game played\n",
    "- 1 for each team in the game\n",
    "- Whether the team won/loss\n",
    "- How many X that team got in that game:\n",
    "    - Points\n",
    "    - Rebounds\n",
    "    - Turnovers\n",
    "    - Assists\n",
    "    - Shots Made\n",
    "    - Shots Missed\n",
    "\n",
    "\n",
    "#### The stats we want:\n",
    "- Points Per Game\n",
    "- Rebounds Per Game\n",
    "- Assists Per Game\n",
    "- Turnovers Per Game\n",
    "- Points Allowed Per Game\n",
    "- Rebounds Allowed Per Game\n",
    "- Assists Allowed Per Game\n",
    "- Turnovers Allowed Per Game\n",
    "- Field Goal Percent\n",
    "- Whether the team played the day before (Back to Back)\n",
    "\n",
    "#### The plan to get the stats we want:\n",
    "We will look through and get all the aggregate stats we need based off team and order of games played. We will only be looking at games played before the current game as we don't want to use data from the game to predict the game. We will divide by amount of games played to get the averages. Then sort the values based on whether the team was home/away. Set the other column to 0. This will allow us to sum all the values in the table when we group. Since we know each game will have only 1 home team and 1 away team, our grouping will allign.\n",
    "\n",
    "**We first want to reset the index** \\\n",
    "\\\n",
    "Currently it has what I call \"GAMES_LEFT\" which is actually more accurately described as number of games played after this for this team in this season. \\\n",
    "\\\n",
    "This shouldnt be our index since each team shares the same 82 numbers\\\n",
    "\\\n",
    "We also should rename this column to \"GAMES_LEFT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "725a7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.rename(columns = {'index': \"GAMES_LEFT\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf9497",
   "metadata": {},
   "source": [
    "**Next lets add an indicator on whether its a home game or not and lets make a more user friendly way to see who is playing in the game**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87197b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Home\"] = df.MATCHUP.apply(lambda x: 0 if x.__contains__('@') else 1)\n",
    "df[\"Team\"] = df.MATCHUP.apply(lambda x: x.split(\" \")[0])\n",
    "df[\"Opp\"] = df.MATCHUP.apply(lambda x: x.split(\" \")[2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c371f",
   "metadata": {},
   "source": [
    "**Now we need to change the teams record to be that from before the game since we don't want to use POST-game data for PRE-game predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14fb99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, series in df.iterrows():\n",
    "    currentW = series.W\n",
    "    currentL = series.L\n",
    "    if series.WL ==\"W\":\n",
    "        \n",
    "        df.at[idx,'W'] = currentW - 1\n",
    "    else:\n",
    "        df.at[idx,'L'] = currentL - 1\n",
    "df[\"W_PCT\"] = df[\"W\"] / (df[\"L\"] + df[\"W\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc04a65",
   "metadata": {},
   "source": [
    "**Now we add an indicator on whether the home team won or not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e84114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Home_Win\"] = 2\n",
    "for idx, series in df.iterrows():\n",
    "    if df.at[idx, \"Home\"] == 1 and df.at[idx, \"WL\"] == \"W\":\n",
    "        df.at[idx, \"Home_Win\"] = 1\n",
    "    else:\n",
    "        df.at[idx, \"Home_Win\"] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e175f7",
   "metadata": {},
   "source": [
    "**Create a indicator on whether the team played the day before**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5938b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Back_To_Back\"] = 2\n",
    "for idx, series in df.iterrows():\n",
    "    Back_To_Back = 0\n",
    "    if series.GAMES_LEFT != 81:\n",
    "        if (int(df.loc[(idx + 1), \"GAME_DATE\"].split(\" \")[1].split(\",\")[0]) + 1) == int(df.loc[idx, \"GAME_DATE\"].split(\" \")[1].split(\",\")[0]):\n",
    "            Back_To_Back = 1\n",
    "    df.at[idx, \"Back_To_Back\"] = Back_To_Back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1bc415",
   "metadata": {},
   "source": [
    "**Sort that indicator based on whether the team is Home or Away**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Home_Team_B2B\"] = 2\n",
    "df[\"Away_Team_B2B\"] = 2\n",
    "for idx, series in df.iterrows():\n",
    "    if df.at[idx, \"Back_To_Back\"] == 1 :\n",
    "        if df.at[idx, \"Home\"] == 1:\n",
    "            df.at[idx, \"Home_Team_B2B\"] = 1\n",
    "            df.at[idx, \"Away_Team_B2B\"] = 0\n",
    "        else:\n",
    "            df.at[idx, \"Away_Team_B2B\"] = 1\n",
    "            df.at[idx, \"Home_Team_B2B\"] = 0\n",
    "    else:\n",
    "        df.at[idx, \"Away_Team_B2B\"] = 0\n",
    "        df.at[idx, \"Home_Team_B2B\"] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca60a5",
   "metadata": {},
   "source": [
    "**It's now time to add the teams per game averages** \\\n",
    "We will do this by aggregating all stats from games with matching team_ids and Game_IDs lower than the current one and then dividing by the amount of games played.\\\n",
    "\\\n",
    "Then we will sort these stats based on Home or Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12276271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Home_Team_ID\"] = 2 #Team_ID\n",
    "df[\"Away_Team_ID\"] = 2\n",
    "\n",
    "df[\"Home_Team\"] = \"\" #3-letter team identifier (CHI, NYK, GSW...)\n",
    "df[\"Away_Team\"] = \"\"\n",
    "\n",
    "df[\"Home_Team_W_PCT\"] = 2.0 #Wins/Losses\n",
    "df[\"Away_Team_W_PCT\"] = 2.0\n",
    "\n",
    "df[\"Home_Team_PPG\"] = -1.0 #Points per game\n",
    "df[\"Away_Team_PPG\"] = -1.0\n",
    "\n",
    "df[\"Home_Team_RPG\"] = -1.0 #Rebounds per game\n",
    "df[\"Away_Team_RPG\"] = -1.0\n",
    "\n",
    "df[\"Home_FGPCT\"] = -1.0 #Field Goal Percentage\n",
    "df[\"Away_FGPCT\"] = -1.0\n",
    "\n",
    "df[\"Home_Team_APG\"] = -1.0 #Assists per game\n",
    "df[\"Away_Team_APG\"] = -1.0\n",
    "\n",
    "df[\"Home_Team_TOVPG\"] = -1.0 #Turnovers per game\n",
    "df[\"Away_Team_TOVPG\"] = -1.0\n",
    "for idx, series in df.iterrows():\n",
    "    team = df.at[idx, \"Team_ID\"]\n",
    "    gameID = df.at[idx, \"Game_ID\"]\n",
    "    \n",
    "    total_points = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID), \"PTS\"].sum()\n",
    "    total_rebounds = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID), \"REB\"].sum()\n",
    "    total_assists = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID), \"AST\"].sum()\n",
    "    total_tov = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID), \"TOV\"].sum()\n",
    "    \n",
    "    PrevFGM = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID), \"FGM\"].sum()\n",
    "    PrevFGA = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID), \"FGA\"].sum()\n",
    "    FGPCT = PrevFGM / PrevFGA\n",
    "    \n",
    "    \n",
    "    if df.at[idx, \"Home\"] == 1:\n",
    "        df.at[idx, \"Home_Team_ID\"] = df.at[idx, \"Team_ID\"] \n",
    "        df.at[idx, \"Away_Team_ID\"] = 0\n",
    "    \n",
    "        df.at[idx, \"Home_Team\"] = df.at[idx, \"Team\"] \n",
    "        df.at[idx, \"Away_Team\"] = df.at[idx, \"Opp\"]\n",
    "        \n",
    "        df.at[idx, \"Home_Team_W_PCT\"] = df.at[idx, \"W_PCT\"]\n",
    "        df.at[idx, \"Away_Team_W_PCT\"] = 0\n",
    "        \n",
    "        df.at[idx, \"Home_Team_PPG\"] = total_points / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)])\n",
    "        df.at[idx, \"Away_Team_PPG\"] = 0\n",
    "        \n",
    "        df.at[idx, \"Home_Team_RPG\"] = total_rebounds / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)])\n",
    "        df.at[idx, \"Away_Team_RPG\"] = 0\n",
    "        \n",
    "        df.at[idx,\"Home_FGPCT\"] = FGPCT\n",
    "        df.at[idx,\"Away_FGPCT\"] = 0.0\n",
    "        \n",
    "        df.at[idx, \"Home_Team_APG\"] = total_assists / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)])\n",
    "        df.at[idx, \"Away_Team_APG\"] = 0\n",
    "        \n",
    "        df.at[idx, \"Home_Team_TOVPG\"] = total_tov / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)])\n",
    "        df.at[idx, \"Away_Team_TOVPG\"] = 0\n",
    "    else:\n",
    "        df.at[idx, \"Home_Team_ID\"] = 0\n",
    "        df.at[idx, \"Away_Team_ID\"] = df.at[idx, \"Team_ID\"]\n",
    "        \n",
    "        df.at[idx, \"Home_Team\"] = df.at[idx, \"Opp\"]\n",
    "        df.at[idx, \"Away_Team\"] = df.at[idx, \"Team\"]\n",
    "        \n",
    "        df.at[idx, \"Home_Team_W_PCT\"] = 0\n",
    "        df.at[idx, \"Away_Team_W_PCT\"] = df.at[idx, \"W_PCT\"]\n",
    "        \n",
    "        df.at[idx, \"Away_Team_PPG\"] = total_points / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)])\n",
    "        df.at[idx, \"Home_Team_PPG\"] = 0\n",
    "        \n",
    "        df.at[idx, \"Away_Team_RPG\"] = total_rebounds / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)])\n",
    "        df.at[idx, \"Home_Team_RPG\"] = 0\n",
    "        \n",
    "        df.at[idx,\"Home_FGPCT\"] = 0.0\n",
    "        df.at[idx,\"Away_FGPCT\"] = FGPCT\n",
    "        \n",
    "        df.at[idx, \"Away_Team_APG\"] = total_assists / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)])\n",
    "        df.at[idx, \"Home_Team_APG\"] = 0\n",
    "        \n",
    "        df.at[idx, \"Away_Team_TOVPG\"] = total_tov / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)])\n",
    "        df.at[idx, \"Home_Team_TOVPG\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f854f25",
   "metadata": {},
   "source": [
    "**Similarly, we now add the team's allowed stats per game**\\\n",
    "This is done just like before however we need to find our the opponents stats for each game and aggregrate those \\\n",
    "\\\n",
    "And course sort by Home/Away\\\n",
    "\\\n",
    "*Note: These are not efficient and do take some time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31008be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Home_PAPG\"] = -1.0 #Points allowed per game\n",
    "df[\"Away_PAPG\"] = -1.0\n",
    "\n",
    "df[\"Home_RAPG\"] = -1.0 #Rebounds allowed per game\n",
    "df[\"Away_RAPG\"] = -1.0\n",
    "\n",
    "df[\"Home_AAPG\"] = -1.0 #Assists allowed per game\n",
    "df[\"Away_AAPG\"] = -1.0\n",
    "\n",
    "df[\"Home_TOVAPG\"] = -1.0 #Turnovers allowed per game\n",
    "df[\"Away_TOVAPG\"] = -1.0\n",
    "for idx, series in df.iterrows():\n",
    "    team = df.at[idx, \"Team_ID\"]\n",
    "    gameID = df.at[idx, \"Game_ID\"]\n",
    "    \n",
    "    PA = 0 #Points Allowed\n",
    "    RA = 0 #Rebounds Allowed\n",
    "    AA = 0 #Assists Allowed\n",
    "    TOVA = 0 #Turnovers Allowed\n",
    "    \n",
    "    GP = 0 #Games Played\n",
    "    for idx2, series2 in df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] < gameID)].iterrows():\n",
    "        opp = series2.Opp\n",
    "        gameID2 = series2.Game_ID\n",
    "        \n",
    "        PA += df.loc[(df[\"Team\"] == opp) & (df[\"Game_ID\"] == gameID2), \"PTS\"].sum()\n",
    "        RA += df.loc[(df[\"Team\"] == opp) & (df[\"Game_ID\"] == gameID2), \"REB\"].sum()\n",
    "        AA += df.loc[(df[\"Team\"] == opp) & (df[\"Game_ID\"] == gameID2), \"AST\"].sum()\n",
    "        TOVA += df.loc[(df[\"Team\"] == opp) & (df[\"Game_ID\"] == gameID2), \"TOV\"].sum()\n",
    "        \n",
    "        GP += 1\n",
    "        \n",
    "    PAPG = 0 #Points allowed per game\n",
    "    TOVAPG = 0 #Turnovers allowed per game\n",
    "    RAPG = 0 #Rebounds allowed per game\n",
    "    AAPG = 0 #Assists allowed per game\n",
    "    \n",
    "    if GP >0:\n",
    "        PAPG = PA/ GP\n",
    "        RAPG = RA/GP\n",
    "        AAPG = AA/ GP\n",
    "        TOVAPG = TOVA/ GP\n",
    "        \n",
    "    if df.at[idx, \"Home\"] == 1:\n",
    "        df.at[idx,\"Home_PAPG\"] = PAPG\n",
    "        df.at[idx,\"Away_PAPG\"] = 0.0\n",
    "        \n",
    "        df.at[idx,\"Home_RAPG\"] = RAPG\n",
    "        df.at[idx,\"Away_RAPG\"] = 0.0\n",
    "        \n",
    "        df.at[idx,\"Home_AAPG\"] = AAPG\n",
    "        df.at[idx,\"Away_AAPG\"] = 0.0\n",
    "        \n",
    "        df.at[idx,\"Home_TOVAPG\"] = TOVAPG\n",
    "        df.at[idx,\"Away_TOVAPG\"] = 0.0\n",
    "    else:\n",
    "        df.at[idx,\"Home_PAPG\"] = 0.0\n",
    "        df.at[idx,\"Away_PAPG\"] = PAPG\n",
    "        \n",
    "        df.at[idx,\"Home_RAPG\"] = 0.0\n",
    "        df.at[idx,\"Away_RAPG\"] = RAPG\n",
    "        \n",
    "        df.at[idx,\"Home_AAPG\"] = 0.0\n",
    "        df.at[idx,\"Away_AAPG\"] = AAPG\n",
    "        \n",
    "        df.at[idx,\"Home_TOVAPG\"] = 0.0\n",
    "        df.at[idx,\"Away_TOVAPG\"] = TOVAPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9961d81",
   "metadata": {},
   "source": [
    "**Next, we drop all the columns we do not need anymore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f473dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"GAMES_LEFT\", \"GAME_DATE\", \"MATCHUP\", \"Team_ID\", \"Team\", \"Opp\", \"W\", \"L\", \"WL\", \"Home\", \"Back_To_Back\", \n",
    "         \"W_PCT\",\"PTS\", \"REB\", \"MIN\", \"FGM\", \"FGA\", \"FG_PCT\", \"FTM\", \"FTA\", \"FT_PCT\", \"OREB\", \"DREB\", \"AST\", \n",
    "         \"STL\", \"BLK\", \"TOV\", \"PF\", \"FG3M\", \"FG3A\", \"FG3_PCT\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10290d6a",
   "metadata": {},
   "source": [
    "**All null values are caused by games played = 0 so we can set the default value to 0 since all other values at the start of the season are 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff742fba",
   "metadata": {},
   "source": [
    "**Finally we can group by Game_ID**\\\n",
    "*We also group by Team and Opp so its more user friendly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ef3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(by = [\"Game_ID\", \"Home_Team\", \"Away_Team\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f99d7",
   "metadata": {},
   "source": [
    "**grouped_df consists of one particular season. I ran the above code for 5 seasons (2014-2018)** \\\n",
    "I did not include the 2019-2020 season since it was interrupted by Covid-19 and the 2020-2021 season was shortened to 72 games. I believe these seasons can still be useful, I just decided not to use them here.\\\n",
    "**I stored each season into their own dataframe then concatenated everything and sent that to a csv file (complete_games)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#grouped14 = grouped_df.copy()\n",
    "#grouped15 = grouped_df.copy()\n",
    "#grouped16 = grouped_df.copy()\n",
    "#grouped17 = grouped_df.copy()\n",
    "#grouped18 = grouped_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete_df = pd.concat([grouped14, grouped15, grouped16, grouped17, grouped18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4692ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete_df.to_csv(\"complete_games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ae3c94",
   "metadata": {},
   "source": [
    "## C. Train and Test the model\n",
    "\\\n",
    "\\\n",
    "**First import all nessecary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5b93797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed1799",
   "metadata": {},
   "source": [
    "- We will use train_test_split to split the data\n",
    "- classification_report to test the model\n",
    "- confusion_matrix to help illustrate the results\n",
    "- We will use 3 Models:\n",
    "    - Logistic Regression\n",
    "    - Logistic Regression with a balanced class weight\n",
    "    - Random Forest Classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddc9168",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d56ee7",
   "metadata": {},
   "source": [
    "**First Split the data into the training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1198c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = complete_df[[ \"Home_Team_PPG\", \"Away_Team_PPG\", \"Home_Team_RPG\", \"Away_Team_RPG\", \"Home_RAPG\", \"Away_RAPG\",\n",
    "               \"Home_FGPCT\", \"Away_FGPCT\", \"Home_PAPG\", \"Away_PAPG\", \"Home_Team_APG\", \"Away_Team_APG\",\n",
    "                \"Home_AAPG\", \"Away_AAPG\", \"Home_Team_TOVPG\", \"Away_Team_TOVPG\", \"Home_TOVAPG\", \"Away_TOVAPG\",\n",
    "                \"Home_Team_B2B\", \"Away_Team_B2B\"]]\n",
    "y= complete_df[\"Home_Win\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb968699",
   "metadata": {},
   "source": [
    "**Now create and fit the modelx using the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1250d2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1500)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(max_iter= 1000)\n",
    "logmodel.fit(X_train, y_train)\n",
    "\n",
    "logmodel_bal = LogisticRegression(max_iter= 1000, class_weight='balanced')\n",
    "logmodel_bal.fit(X_train, y_train)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators= 1500)\n",
    "rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a785c4a",
   "metadata": {},
   "source": [
    "**Lastly create our predictions and test them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a91db52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.41      0.50       871\n",
      "           1       0.65      0.84      0.73      1159\n",
      "\n",
      "    accuracy                           0.65      2030\n",
      "   macro avg       0.65      0.62      0.62      2030\n",
      "weighted avg       0.65      0.65      0.63      2030\n",
      "\n",
      "[[353 518]\n",
      " [185 974]]\n",
      "\n",
      "\n",
      "logbal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.60       871\n",
      "           1       0.70      0.67      0.69      1159\n",
      "\n",
      "    accuracy                           0.65      2030\n",
      "   macro avg       0.65      0.65      0.65      2030\n",
      "weighted avg       0.65      0.65      0.65      2030\n",
      "\n",
      "[[541 330]\n",
      " [377 782]]\n",
      "\n",
      "\n",
      "rfc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50       871\n",
      "           1       0.65      0.81      0.72      1159\n",
      "\n",
      "    accuracy                           0.64      2030\n",
      "   macro avg       0.63      0.61      0.61      2030\n",
      "weighted avg       0.64      0.64      0.63      2030\n",
      "\n",
      "[[367 504]\n",
      " [225 934]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_log = logmodel.predict(X_test)\n",
    "print(\"log\")\n",
    "print(classification_report(y_test, predictions_log))\n",
    "print(confusion_matrix(y_test, predictions_log))\n",
    "print(\"\\n\")\n",
    "predictions_logbal = logmodel_bal.predict(X_test)\n",
    "print(\"logbal\")\n",
    "print(classification_report(y_test, predictions_logbal))\n",
    "print(confusion_matrix(y_test, predictions_logbal))\n",
    "print(\"\\n\")\n",
    "predictions_rfc = rfc.predict(X_test)\n",
    "print(\"rfc\")\n",
    "print(classification_report(y_test, predictions_rfc))\n",
    "print(confusion_matrix(y_test, predictions_rfc))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b4291",
   "metadata": {},
   "source": [
    "Overall the Logistic Regression model has 65% accuracy. It has:\\\n",
    "\\\n",
    "-353 True Positives (Correctly Predicted Away Win)\\\n",
    "-185 False Positives (Predicted Away Win when it was a Home Win)\\\n",
    "-974 True Negatives (Correctly Predicted Home Win)\\\n",
    "-518 False Negatives(Predicted Home Win when it was a Away Win\\\n",
    "\\\n",
    "We can interpret from these results that this model over predicts Home Wins\\\n",
    "\\\n",
    "The Log model with balanced weights has a similar accuracy but more evenly predicts outcomes with only 54% of home wins predcited\\\n",
    "\\\n",
    "The Random Forest Classifier preformed similarly to the original Log model, but slightly worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e66e2e",
   "metadata": {},
   "source": [
    "## 2. Creating The App\n",
    "### A. Retrieve the Data\n",
    "We will gather the data the same way we did earlier but with the current season selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e640876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_dict = teams.get_teams()\n",
    "df = pd.DataFrame()\n",
    "for team in team_dict:\n",
    "    #print(team[\"full_name\"])\n",
    "    gamelogobj = teamgamelog.TeamGameLog(team_id = str(team[\"id\"]), season = \"2021\")\n",
    "    gamelogdf = gamelogobj.get_data_frames()[0]\n",
    "    df = pd.concat([df, gamelogdf])\n",
    "    sleep(.750)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ef42b",
   "metadata": {},
   "source": [
    "### B. Adjust Data and Add Features \n",
    "Again this will be just like before but this time with some slight adjustments, most notably:\n",
    "1. We don't want to group this data so we dont need to sort the values into Home/Away\n",
    "2. We don't solve for back to back games in the dataframe but rather calculate the day of their last game\n",
    "3. We will be using the current game played in the per game averages calculations since we aren't trying to predict its outcome, but rather the game after that (not in the dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39373d7b",
   "metadata": {},
   "source": [
    "First lets reset index like we did before, and rename the unnamed column (was named GAMES_LEFT above) to GAMES_PLAYED_AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3dcf76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)\n",
    "df = df.rename(columns = {'index': \"GAMES_PLAYED_AFTER\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f5af5",
   "metadata": {},
   "source": [
    "Next we split up the two teams and calculate the day the game was played (Looking for the DD part of MM-DD-YYYY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2565b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Team\"] = df.MATCHUP.apply(lambda x: x.split(\" \")[0])\n",
    "df[\"Opp\"] = df.MATCHUP.apply(lambda x: x.split(\" \")[2])\n",
    "df[\"Day\"] = df.GAME_DATE.apply(lambda x: x.split(\" \")[1].split(\",\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c36e9",
   "metadata": {},
   "source": [
    "Now lets calculate the per game averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "61289745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PPG\"] = -1.0\n",
    "df[\"RPG\"] = -1.0\n",
    "df[\"FGPCT\"] = -1.0\n",
    "df[\"APG\"] = -1.0\n",
    "df[\"TOVPG\"] = -1.0\n",
    "\n",
    "for idx, series in df.iterrows():\n",
    "    team = df.at[idx, \"Team_ID\"]\n",
    "    gameID = df.at[idx, \"Game_ID\"]\n",
    "    \n",
    "    total_points = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID), \"PTS\"].sum()\n",
    "    total_rebounds = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID), \"REB\"].sum()\n",
    "    total_assists = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID), \"AST\"].sum()\n",
    "    total_tov = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID), \"TOV\"].sum()\n",
    "    \n",
    "    PrevFGM = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID), \"FGM\"].sum()\n",
    "    PrevFGA = df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID), \"FGA\"].sum()\n",
    "    FGPCT = PrevFGM / PrevFGA\n",
    "    \n",
    "    df.at[idx, \"Team_ID\"] = df.at[idx, \"Team_ID\"] #Team_ID\n",
    "    df.at[idx, \"PPG\"] = total_points / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID)]) \n",
    "    df.at[idx, \"RPG\"] = total_rebounds / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID)])\n",
    "    df.at[idx,\"FGPCT\"] = FGPCT\n",
    "    df.at[idx, \"APG\"] = total_assists / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID)])   \n",
    "    df.at[idx, \"TOVPG\"] = total_tov / len(df[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fdb9d",
   "metadata": {},
   "source": [
    "Next is the per game allowed averages. \\\n",
    "Since we will only be caring about each teams most recent stats, we can speed this up by only calculating these stats for the lastest game.\\\n",
    "GAMES_PLAYED_AFTER keeps track of how many games in the dataframe occur after that one for each team, so 0 games played after is the most recent game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9607b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PAPG\"] = -1.0\n",
    "df[\"RAPG\"] = -1.0\n",
    "df[\"AAPG\"] = -1.0\n",
    "df[\"TOVAPG\"] = -1.0\n",
    "\n",
    "for idx, series in df.iterrows():\n",
    "    team = df.at[idx, \"Team_ID\"]\n",
    "    gameID = df.at[idx, \"Game_ID\"]\n",
    "    \n",
    "    PA = 0 #Points Allowed\n",
    "    RA = 0 #Rebounds Allowed\n",
    "    AA = 0 #Assists Allowed\n",
    "    TOVA = 0 #Turnovers Allowed\n",
    "    \n",
    "    GP = 0 #Games Played\n",
    "    if series.GAMES_PLAYED_AFTER == 0:\n",
    "        for idx2, series2 in df.loc[(df[\"Team_ID\"] == team) & (df[\"Game_ID\"] <= gameID)].iterrows():\n",
    "            opp = series2.Opp\n",
    "            gameID2 = series2.Game_ID\n",
    "\n",
    "            PA += df.loc[(df[\"Team\"] == opp) & (df[\"Game_ID\"] == gameID2), \"PTS\"].sum()\n",
    "            RA += df.loc[(df[\"Team\"] == opp) & (df[\"Game_ID\"] == gameID2), \"REB\"].sum()\n",
    "            AA += df.loc[(df[\"Team\"] == opp) & (df[\"Game_ID\"] == gameID2), \"AST\"].sum()\n",
    "            TOVA += df.loc[(df[\"Team\"] == opp) & (df[\"Game_ID\"] == gameID2), \"TOV\"].sum()\n",
    "\n",
    "            GP += 1\n",
    "\n",
    "        PAPG = 0 #Points allowed per game\n",
    "        TOVAPG = 0 #Turnovers allowed per game\n",
    "        RAPG = 0 #Rebounds allowed per game\n",
    "        AAPG = 0 #Assists allowed per game\n",
    "\n",
    "        if GP >0:\n",
    "            PAPG = PA/ GP\n",
    "            RAPG = RA/GP\n",
    "            AAPG = AA/ GP\n",
    "            TOVAPG = TOVA/ GP\n",
    "\n",
    "\n",
    "        df.at[idx,\"PAPG\"] = PAPG\n",
    "        df.at[idx,\"RAPG\"] = RAPG\n",
    "        df.at[idx,\"AAPG\"] = AAPG\n",
    "        df.at[idx,\"TOVAPG\"] = TOVAPG\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076633a5",
   "metadata": {},
   "source": [
    "Then we will drop the unnessecary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3ebc42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"MATCHUP\", \"Opp\", \"W\", \"L\", \"WL\", \"Game_ID\", \"GAME_DATE\",\n",
    "         \"W_PCT\",\"PTS\", \"REB\", \"MIN\", \"FGM\", \"FGA\", \"FG_PCT\", \"FTM\", \"FTA\", \"FT_PCT\", \"OREB\", \"DREB\", \"AST\", \n",
    "         \"STL\", \"BLK\", \"TOV\", \"PF\", \"FG3M\", \"FG3A\", \"FG3_PCT\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048022a",
   "metadata": {},
   "source": [
    "Now instead of grouping, we are going to create a new data of only the most recent stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2cc7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_stats = df[df[\"GAMES_PLAYED_AFTER\"] == 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef012b62",
   "metadata": {},
   "source": [
    "And we can drop that column now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32b0d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_stats.drop([\"GAMES_PLAYED_AFTER\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "97ceb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f24d8",
   "metadata": {},
   "source": [
    "### C. Create function that takes in a team and day and outputs the probabilities\n",
    "This is very simple. We will just need to find each teams corresponding value from current_stats, format them in an array, then use that array for each of our models\n",
    "\n",
    "*Note this takes in the day from before the game. This is to prevent issues on the first of each month.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "09a81310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(Home, Away, Day):\n",
    "    \n",
    "    HomePPG = current_stats.loc[current_stats[\"Team\"] == Home, \"PPG\"].sum()\n",
    "    AwayPPG = current_stats.loc[current_stats[\"Team\"] == Away, \"PPG\"].sum()\n",
    "    \n",
    "    HomeRPG = current_stats.loc[current_stats[\"Team\"] == Home, \"RPG\"].sum()\n",
    "    AwayRPG = current_stats.loc[current_stats[\"Team\"] == Away, \"RPG\"].sum()\n",
    "    \n",
    "    HomeRAPG = current_stats.loc[current_stats[\"Team\"] == Home, \"RAPG\"].sum()\n",
    "    AwayRAPG = current_stats.loc[current_stats[\"Team\"] == Away, \"RAPG\"].sum()\n",
    "    \n",
    "    Home_FGPCT = current_stats.loc[current_stats[\"Team\"] == Home, \"FGPCT\"].sum()\n",
    "    Away_FGPCT = current_stats.loc[current_stats[\"Team\"] == Away, \"FGPCT\"].sum()\n",
    "    \n",
    "    Home_PAPG = current_stats.loc[current_stats[\"Team\"] == Home, \"PAPG\"].sum()\n",
    "    Away_PAPG = current_stats.loc[current_stats[\"Team\"] == Away, \"PAPG\"].sum()\n",
    "    \n",
    "    Home_Team_APG = current_stats.loc[current_stats[\"Team\"] == Home, \"APG\"].sum()\n",
    "    Away_Team_APG = current_stats.loc[current_stats[\"Team\"] == Away, \"APG\"].sum()\n",
    "    \n",
    "    Home_AAPG = current_stats.loc[current_stats[\"Team\"] == Home, \"AAPG\"].sum()\n",
    "    Away_AAPG = current_stats.loc[current_stats[\"Team\"] == Away, \"AAPG\"].sum()\n",
    "    \n",
    "    Home_Team_TOVPG = current_stats.loc[current_stats[\"Team\"] == Home, \"TOVPG\"].sum()\n",
    "    Away_Team_TOVPG = current_stats.loc[current_stats[\"Team\"] == Away, \"TOVPG\"].sum()\n",
    "    \n",
    "    Home_TOVAPG = current_stats.loc[current_stats[\"Team\"] == Home, \"TOVAPG\"].sum()\n",
    "    Away_TOVAPG = current_stats.loc[current_stats[\"Team\"] == Away, \"TOVAPG\"].sum()\n",
    "    \n",
    "    if current_stats.loc[current_stats[\"Team\"] == Home, \"Day\"].sum() == Day:\n",
    "        Home_Team_B2B = 1\n",
    "        print(\"htb2b\")\n",
    "    else:\n",
    "        Home_Team_B2B = 0\n",
    "    if current_stats.loc[current_stats[\"Team\"] == Away, \"Day\"].sum() == Day:\n",
    "        Away_Team_B2B = 1\n",
    "        print(\"atb2b\")\n",
    "    else:\n",
    "        Away_Team_B2B = 0\n",
    "        \n",
    "    arr = [\n",
    "        HomePPG,\n",
    "        AwayPPG,\n",
    "        \n",
    "        HomeRPG,\n",
    "        AwayRPG,\n",
    "    \n",
    "        HomeRAPG,\n",
    "        AwayRAPG,\n",
    "    \n",
    "        Home_FGPCT,\n",
    "        Away_FGPCT,\n",
    "\n",
    "        Home_PAPG,\n",
    "        Away_PAPG,\n",
    "\n",
    "        Home_Team_APG,\n",
    "        Away_Team_APG,\n",
    "\n",
    "        Home_AAPG,\n",
    "        Away_AAPG,\n",
    "\n",
    "        Home_Team_TOVPG,\n",
    "        Away_Team_TOVPG,\n",
    "\n",
    "        Home_TOVAPG,\n",
    "        Away_TOVAPG,\n",
    "\n",
    "        Home_Team_B2B,\n",
    "        Away_Team_B2B\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    print(arr[0:2]) #Check if teams were inputted correctly\n",
    "    \n",
    "    pred_log = logmodel.predict_proba([arr])\n",
    "    pred_logbal = logmodel_bal.predict_proba([arr])\n",
    "    pred_rfc = rfc.predict_proba([arr])\n",
    "    \n",
    "    \n",
    "    return [pred_log, pred_logbal, pred_rfc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "46250acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111.67948717948718, 115.0]\n"
     ]
    }
   ],
   "source": [
    "# (\"HOME\", \"AWAY\", \"YESTERDAY'S DATE\" (\"DD\"))\n",
    "# ( \"CHI\", \"PHI\", \"09\")\n",
    "# Full list of team abbreviations are below\n",
    "# Will output team PPG if inputted correctly, else it will output 0\n",
    "\n",
    "a = Predict(\"CHI\", \"MIL\", \"04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7d388a8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Model:                0.563548\n",
      "Blanced Log Model:        0.47746438\n",
      "Random Forest Classifier: 0.68133333\n",
      "Average:                  0.5741152366666668\n"
     ]
    }
   ],
   "source": [
    "print(\"Log Model:                \" + str(a[0]).split(\" \")[1].split(\"]\")[0])\n",
    "print(\"Blanced Log Model:        \" + str(a[1]).split(\" \")[1].split(\"]\")[0])\n",
    "print(\"Random Forest Classifier: \" + str(a[2]).split(\" \")[1].split(\"]\")[0])\n",
    "print(\"Average:                  \" + str((float(str(a[0]).split(\" \")[1].split(\"]\")[0]) + float(str(a[1]).split(\" \")[1].split(\"]\")[0]) + float(str(a[2]).split(\" \")[1].split(\"]\")[0]))/3))\n",
    "\n",
    "#Outputs chance for a home team win"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce850f9b",
   "metadata": {},
   "source": [
    "ATL\tAtlanta Hawks\\\n",
    "BKN\tBrooklyn Nets\\\n",
    "BOS\tBoston Celtics\\\n",
    "CHA\tCharlotte Hornets\\\n",
    "CHI\tChicago Bulls\\\n",
    "CLE\tCleveland Cavaliers\\\n",
    "DAL\tDallas Mavericks\\\n",
    "DEN\tDenver Nuggets\\\n",
    "DET\tDetroit Pistons\\\n",
    "GSW\tGolden State Warriors\\\n",
    "HOU\tHouston Rockets\\\n",
    "IND\tIndiana Pacers\\\n",
    "LAC\tLos Angeles Clippers\\\n",
    "LAL\tLos Angeles Lakers\\\n",
    "MEM\tMemphis Grizzlies\\\n",
    "MIA\tMiami Heat\\\n",
    "MIL\tMilwaukee Bucks\\\n",
    "MIN\tMinnesota Timberwolves\\\n",
    "NOP\tNew Orleans Pelicans\\\n",
    "NYK\tNew York Knicks\\\n",
    "OKC\tOklahoma City Thunder\\\n",
    "ORL\tOrlando Magic\\\n",
    "PHI\tPhiladelphia 76ers\\\n",
    "PHX\tPhoenix Suns\\\n",
    "POR\tPortland Trail Blazers\\\n",
    "SAC\tSacramento Kings\\\n",
    "SAS\tSan Antonio Spurs\\\n",
    "TOR\tToronto Raptors\\\n",
    "UTA\tUtah Jazz\\\n",
    "WAS\tWashington Wizards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
